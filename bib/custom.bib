@misc{pulsiphergames,
    author = {Lewis Pulsipher},
    title = {The Art of Negotiation in Diplomacy},
    howpublished = {\url{https://pulsiphergames.com/diplomacy/ArtofNegotiation.htm}},
    note = {Accessed: 2024-02-11},
    year = {1982}
}

@article{anderson_encounter_1994,
	title = {Encounter with reality: {Children}'s reactions on discovering the {Santa} {Claus} myth},
	volume = {25},
	issn = {1573-3327},
	url = {https://doi.org/10.1007/BF02253287},
	doi = {10.1007/BF02253287},
	abstract = {Fifty-two children who no longer believed in Santa Claus were individually administered a structured interview on their reactions to discovering the truth. Their parents completed a questionnaire assessing their initial encouragement of the child to believe in Santa and rating their child's reactions to discovering the truth as well as their own reactions to the child's discovery. Parental encouragement for the child to believe was very strong. Children generally discovered the truth on their own at age seven. Children reported predominantly positive reactions on learning the truth. Parents, however, described themselves as predominantly sad in reaction to their child's discovery.},
	number = {2},
	journal = {Child Psychiatry and Human Development},
	author = {Anderson, Carl J. and Prentice, Norman M.},
	month = dec,
	year = {1994},
	pages = {67--84},
}

% diplomacy-related

@inproceedings{NEURIPS2019_84b20b1f,
 author = {Paquette, Philip and Lu, Yuchen and BOCCO, SETON STEVEN and Smith, Max and O.-G., Satya and Kummerfeld, Jonathan K. and Pineau, Joelle and Singh, Satinder and Courville, Aaron C},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = nips,
 title = {No-Press Diplomacy: Modeling Multi-Agent Gameplay},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/84b20b1f5a0d103f5710bb67a043cd78-Paper.pdf},
 year = {2019}
}

% SillyNegoBot
@inproceedings{polberg2011developing,
  title={Developing intelligent bots for the {D}iplomacy game},
  author={Polberg, Sylwia and Paprzycki, Marcin and Ganzha, Maria},
  booktitle={2011 Federated Conference on Computer Science and Information Systems (FedCSIS)},
  pages={589--596},
  year={2011},
  organization={IEEE},
url={https://ieeexplore.ieee.org/document/6078245}
}
% dipblue
@inproceedings{ferreira2015strategic,
  title={Strategic {N}egotiation and {T}rust in {D}iplomacy--the {D}ip{B}lue {A}pproach},
  author={Ferreira, Andr{\'e} and Lopes Cardoso, Henrique and Reis, Lu{\'\i}s Paulo},
  booktitle={Transactions on Computational Collective Intelligence XX},
  pages={179--200},
  year={2015},
  publisher="Springer International Publishing",
doi="10.1007/978-3-319-27543-7_9",
url="https://doi.org/10.1007/978-3-319-27543-7_9"
}
% deepmind negotiation bot
@article{kramar2022negotiation,
  title={Negotiation and honesty in artificial intelligence methods for the board game of {D}iplomacy},
  author={Kram{\'a}r, J{\'a}nos and Eccles, Tom and Gemp, Ian and Tacchetti, Andrea and McKee, Kevin R and Malinowski, Mateusz and Graepel, Thore and Bachrach, Yoram},
  journal={Nature Communications},
  volume={13},
  number={1},
  pages={7214},
  year={2022},
  publisher={Nature Publishing Group UK London},
doi={10.1038/s41467-022-34473-5}
}
% meta cicero
@article{meta2022human,
author = {Anton Bakhtin and Noam Brown  and Emily Dinan  and Gabriele Farina  and Colin Flaherty  and Daniel Fried  and Andrew Goff  and Jonathan Gray  and Hengyuan Hu  and Athul Paul Jacob  and Mojtaba Komeili  and Karthik Konath  and Minae Kwon  and Adam Lerer  and Mike Lewis  and Alexander H. Miller  and Sasha Mitts  and Adithya Renduchintala  and Stephen Roller  and Dirk Rowe  and Weiyan Shi  and Joe Spisak  and Alexander Wei  and David Wu  and Hugh Zhang  and Markus Zijlstra },
title = {Human-level play in the game of {D}iplomacy by combining language models with strategic reasoning},
journal = {Science},
volume = {378},
number = {6624},
pages = {1067-1074},
year = {2022},
doi = {10.1126/science.ade9097},
URL = {https://www.science.org/doi/abs/10.1126/science.ade9097},
eprint = {https://www.science.org/doi/pdf/10.1126/science.ade9097}}

@inproceedings{peskov2020takes,
    title = "It Takes Two to Lie: One to Lie, and One to Listen",
    author = "Peskov, Denis  and
      Cheng, Benny  and
      Elgohary, Ahmed  and
      Barrow, Joe  and
      Danescu-Niculescu-Mizil, Cristian  and
      Boyd-Graber, Jordan",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.353",
    doi = "10.18653/v1/2020.acl-main.353",
}

@inproceedings{LDC2020,
  author={Knight, Kevin and Badarau, Bianca and Baranescu, Laura and Bonial, Claire and Bardocz, Madalina and Griffitt, Kira and Hermjakob, Ulf and Marcu, Daniel and Palmer, Martha and O'Gorman, Tim and Schneider, Nathan},
  publisher = {Linguistic Data Consortium},
  title = {Abstract {M}eaning {R}epresentation ({AMR}) {A}nnotation {R}elease 3.0},
  doi = {10.35111/44cy-bp51},
  year={2020}
}

@article{bakhtin2021no,
  title={No-{P}ress {D}iplomacy from {S}cratch},
  author={Bakhtin, Anton and Wu, David and Lerer, Adam and Brown, Noam},
  journal=nips,
  year={2021},
    url={https://proceedings.neurips.cc/paper/2021/file/95f2b84de5660ddf45c8a34933a2e66f-Paper.pdf}
}
@article{gray2020human,
  title={{H}uman-{L}evel {P}erformance in {N}o-{P}ress {D}iplomacy via {E}quilibrium {S}earch},
  author={Gray, Jonathan and Lerer, Adam and Bakhtin, Anton and Brown, Noam},
  journal=iclr,
  year={2021},
url={https://openreview.net/forum?id=0-uUGPbIjD}
}
@article{anthony2020learning,
  title={{L}earning to {P}lay {N}o-{P}ress {D}iplomacy
with {B}est {R}esponse {P}olicy {I}teration},
  author={Anthony, Thomas and Eccles, Tom and Tacchetti, Andrea and Kram{\'a}r, J{\'a}nos and Gemp, Ian and Hudson, Thomas and Porcel, Nicolas and Lanctot, Marc and P{\'e}rolat, Julien and Everett, Richard and others},
  journal=nips,
  year={2020},
    url={https://proceedings.neurips.cc/paper/2020/file/d1419302db9c022ab1d48681b13d5f8b-Paper.pdf}
}

@inproceedings{wongkamjan-etal-2024-victories,
    title = "More {V}ictories, {L}ess {C}ooperation: {A}ssessing {C}icero`s {D}iplomacy {P}lay",
    author = "Wongkamjan, Wichayaporn  and
      Gu, Feng  and
      Wang, Yanze  and
      Hermjakob, Ulf  and
      May, Jonathan  and
      Stewart, Brandon  and
      Kummerfeld, Jonathan  and
      Peskoff, Denis  and
      Boyd-Graber, Jordan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.672/",
    doi = "10.18653/v1/2024.acl-long.672",
    pages = "12423--12441",
    abstract = "The boardgame Diplomacy is a challenging setting for communicative and cooperative artificial intelligence. The most prominent communicative Diplomacy AI, Cicero, has excellent strategic abilities, exceeding human players. However, the best Diplomacy players master communication, not just tactics, which is why the game has received attention as an AI challenge. This work seeks to understand the degree to which Cicero succeeds at communication. First, we annotate in-game communication with abstract meaning representation to separate in-game tactics from general language. Second, we run two dozen games with humans and Cicero, totaling over 200 human-player hours of competition. While AI can consistently outplay human players, AI-Human communication is still limited because of AI`s difficulty with deception and persuasion. This shows that Cicero relies on strategy and has not yet reached the full promise of communicative and cooperative AI."
}
@inproceedings{
bakhtin2023mastering,
title={Mastering the {G}ame of {N}o-{P}ress {D}iplomacy via {H}uman-{R}egularized {R}einforcement {L}earning and {P}lanning},
author={Anton Bakhtin and David J Wu and Adam Lerer and Jonathan Gray and Athul Paul Jacob and Gabriele Farina and Alexander H Miller and Noam Brown},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=F61FwJTZhb}
}

@book{bok2011lying,
  title={Lying: {M}oral {C}hoice in {P}ublic and {P}rivate {L}ife},
  author={Bok, Sissela},
  year={2011},
  publisher={Vintage}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal=nips,
  volume={30},
  year={2017},
url={https://proceedings.neurips.cc/paper_files/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf}
}
@article{shu2017fake,
  title={Fake {N}ews {D}etection on {S}ocial
        {M}edia: {A} {D}ata {M}ining {P}erspective},
  author={Shu, Kai and Sliva, Amy and Wang, Suhang and Tang, Jiliang and Liu, Huan},
  journal={ACM SIGKDD explorations newsletter},
  volume={19},
  number={1},
  pages={22--36},
  year={2017},
  publisher={ACM New York, NY, USA},
    url={https://dl.acm.org/doi/abs/10.1145/3137597.3137600}
}

@article{zhou2020fake,
  title={Fake {N}ews {E}arly {D}etection: {A} {T}heory-{D}riven {M}odel},
  author={Zhou, Xinyi and Jain, Atishay and Phoha, Vir V and Zafarani, Reza},
  journal={Digital Threats: Research and Practice},
  volume={1},
  number={2},
  pages={1--25},
  year={2020},
  publisher={ACM New York, NY, USA},
url={https://dl.acm.org/doi/abs/10.1145/3377478}
}

@article{chen2023combating,
  title={Combating {M}isinformation in the {A}ge of {LLMs}: {O}pportunities and {C}hallenges},
  author={Chen, Canyu and Shu, Kai},
  journal={arXiv preprint arXiv:2311.05656},
  year={2023},
url={https://arxiv.org/pdf/2311.05656}
}

@article{park2024ai,
  title={AI {D}eception: {A} {S}urvey of {E}xamples, {R}isks, and {P}otential {S}olutions},
  author={Park, Peter S and Goldstein, Simon and O’Gara, Aidan and Chen, Michael and Hendrycks, Dan},
  journal={Patterns},
  volume={5},
  number={5},
  year={2024},
  publisher={Elsevier}
}

@article{sarkadi2024deceptive,
  title={Deceptive {AI} and {S}ociety},
  author={Sarkadi, {\c{S}}tefan},
  journal={IEEE Technology and society magazine},
  volume={42},
  number={4},
  pages={77--86},
  year={2024},
  publisher={IEEE}
}

@inproceedings{chittaranjan2010you,
  title={Are you {A}werewolf? {D}etecting deceptive roles and outcomes in a conversational role-playing game},
  author={Chittaranjan, Gokul and Hung, Hayley},
  booktitle={2010 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={5334--5337},
  year={2010},
  organization={IEEE}
}
@inproceedings{hancock2017towards,
  title={Towards deception detection in a language-driven game},
  author={Hancock, Will and Floyd, Michael W and Molineaux, Matthew and Aha, David},
  booktitle={The Thirtieth International Flairs Conference},
  year={2017}
}

@phdthesis{girlea2017deception,
  title={Deception detection in dialogues},
  author={Girlea, Codruta Liliana},
  year={2017},
  school={University of Illinois at Urbana-Champaign}
}

@article{palomaki2016machiavelli,
  title={Machiavelli as a poker mate—{A} naturalistic behavioural study on strategic deception},
  author={Palom{\"a}ki, Jussi and Yan, Jeff and Laakasuo, Michael},
  journal={Personality and Individual Differences},
  volume={98},
  pages={266--271},
  year={2016},
  publisher={Elsevier}
}

@mastersthesis{lee2013deception,
  title={Deception and {A}rousal in {T}exas {H}old ‘em {P}oker},
  author={Lee, Jackey and Hin, Ting},
  year={2013},
  school={University of Waterloo}
}
@book{granhag2015detecting,
  title={Detecting deception: {C}urrent challenges and cognitive approaches},
  author={Granhag, P{\"a}r Anders and Vrij, Aldert and Verschuere, Bruno},
  year={2015},
  publisher={John Wiley \& Sons}
}
@article{margot2015quantitative,
  title={A quantitative criterion for defining planets},
  author={Margot, Jean-Luc},
  journal={The Astronomical Journal},
  volume={150},
  number={6},
  pages={185},
  year={2015},
  publisher={IOP Publishing}
}

@article{greenberg1982effect,
  title={The effect of deception on optimal decisions},
  author={Greenberg, Irwin},
  journal={Operations Research Letters},
  volume={1},
  number={4},
  pages={144--147},
  year={1982},
  publisher={Elsevier}
}
@article{ettinger2010theory,
  title={A theory of deception},
  author={Ettinger, David and Jehiel, Philippe},
  journal={American Economic Journal: Microeconomics},
  volume={2},
  number={1},
  pages={1--20},
  year={2010},
  publisher={American Economic Association}
}
@article{zhang2019optimal,
  title={Optimal stealthy deception attack against cyber-physical systems},
  author={Zhang, Qirui and Liu, Kun and Xia, Yuanqing and Ma, Aoyun},
  journal={IEEE transactions on cybernetics},
  volume={50},
  number={9},
  pages={3963--3972},
  year={2019},
  publisher={IEEE}
}

@article{levine2022truth,
  title={Truth-default theory and the psychology of lying and deception detection},
  author={Levine, Timothy R},
  journal={Current Opinion in Psychology},
  volume={47},
  pages={101380},
  year={2022},
  publisher={Elsevier}
}

@book{kahneman2011thinking,
  abstract = {In this work the author, a recipient of the Nobel Prize in Economic Sciences for his seminal work in psychology that challenged the rational model of judgment and decision making, has brought together his many years of research and thinking in one book. He explains the two systems that drive the way we think. System 1 is fast, intuitive, and emotional; System 2 is slower, more deliberative, and more logical. He exposes the extraordinary capabilities, and also the faults and biases, of fast thinking, and reveals the pervasive influence of intuitive impressions on our thoughts and behavior. He reveals where we can and cannot trust our intuitions and how we can tap into the benefits of slow thinking. He offers practical and enlightening insights into how choices are made in both our business and our personal lives, and how we can use different techniques to guard against the mental glitches that often get us into trouble. This author's work has transformed cognitive psychology and launched the new fields of behavioral economics and happiness studies. In this book, he takes us on a tour of the mind and explains the two systems that drive the way we think and the way we make choices.},
  added-at = {2013-01-10T15:41:11.000+0100},
  address = {New York},
  author = {Kahneman, Daniel},
  biburl = {https://www.bibsonomy.org/bibtex/2f322864169411fd5914f3fa5488e288c/schmidt2},
  description = {Thinking, Fast and Slow: Amazon.de: Daniel Kahneman: Englische Bücher},
  interhash = {a1400a299a00de009ec8eda73e6289af},
  intrahash = {f322864169411fd5914f3fa5488e288c},
  isbn = {9780374275631 0374275637},
  keywords = {bib books psychology thinking toread},
  publisher = {Farrar, Straus and Giroux},
  refid = {706020998},
  timestamp = {2013-01-10T15:41:11.000+0100},
  title = {Thinking, fast and slow},
  url = {https://www.amazon.de/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/ref=wl_it_dp_o_pdT1_nS_nC?ie=UTF8&colid=151193SNGKJT9&coliid=I3OCESLZCVDFL7},
  year = 2011
}

@inproceedings{fluri2024evaluating,
  title={Evaluating superhuman models with consistency checks},
  author={Fluri, Lukas and Paleka, Daniel and Tram{\`e}r, Florian},
  booktitle={2024 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
  pages={194--232},
  year={2024},
  organization={IEEE}
}
@inproceedings{azaria-mitchell-2023-internal,
    title = "The Internal State of an {LLM} Knows When It`s Lying",
    author = "Azaria, Amos  and
      Mitchell, Tom",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.68/",
    doi = "10.18653/v1/2023.findings-emnlp.68",
    pages = "967--976",
    abstract = "While Large Language Models (LLMs) have shown exceptional performance in various tasks, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. In this paper, we provide evidence that the LLM`s internal state can be used to reveal the truthfulness of statements. This includes both statements provided to the LLM, and statements that the LLM itself generates. Our approach is to train a classifier that outputs the probability that a statement is truthful, based on the hidden layer activations of the LLM as it reads or generates the statement. Experiments demonstrate that given a set of test sentences, of which half are true and half false, our trained classifier achieves an average of 71{\%} to 83{\%} accuracy labeling which sentences are true versus false, depending on the LLM base model. Furthermore, we explore the relationship between our classifier`s performance and approaches based on the probability assigned to the sentence by the LLM. We show that while LLM-assigned sentence probability is related to sentence truthfulness, this probability is also dependent on sentence length and the frequencies of words in the sentence, resulting in our trained classifier providing a more reliable approach to detecting truthfulness, highlighting its potential to enhance the reliability of LLM-generated content and its practical applicability in real-world scenarios."
}
@misc{burns2024discoveringlatentknowledgelanguage,
      title={Discovering Latent Knowledge in Language Models Without Supervision}, 
      author={Collin Burns and Haotian Ye and Dan Klein and Jacob Steinhardt},
      year={2024},
      eprint={2212.03827},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.03827}, 
}
@article{llama3modelcard,

title={Llama 3 Model Card},

author={AI@Meta},

year={2024},

url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}

}
@inproceedings{banarescu-etal-2013-abstract,
    title = "{A}bstract {M}eaning {R}epresentation for Sembanking",
    author = "Banarescu, Laura  and
      Bonial, Claire  and
      Cai, Shu  and
      Georgescu, Madalina  and
      Griffitt, Kira  and
      Hermjakob, Ulf  and
      Knight, Kevin  and
      Koehn, Philipp  and
      Palmer, Martha  and
      Schneider, Nathan",
    editor = "Pareja-Lora, Antonio  and
      Liakata, Maria  and
      Dipper, Stefanie",
    booktitle = "Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W13-2322/",
    pages = "178--186"
}

@article{gu2024personalized,
  title={Personalized Help for Optimizing Low-Skilled Users' Strategy},
  author={Gu, Feng and Wongkamjan, Wichayaporn and Boyd-Graber, Jordan Lee and Kummerfeld, Jonathan K and Peskoff, Denis and May, Jonathan},
  journal={arXiv preprint arXiv:2411.09109},
  year={2024}
}

@book{ekman2003,
  author    = {Paul Ekman},
  title     = {Emotions Revealed: Recognizing Faces and Feelings to Improve Communication and Emotional Life},
  publisher = {Times Books},
  year      = {2003},
  address   = {New York},
}

@article{depaulo2003,
  author    = {B. M. DePaulo and S. A. Kashy and M. Kirkendol, et al.},
  title     = {Cues to Deception},
  journal   = {Psychological Bulletin},
  volume    = {129},
  number    = {1},
  pages     = {74--118},
  year      = {2003},
}

@book{vrij2008,
  author    = {Adrian Vrij},
  title     = {Detecting Lies and Deceit: Pitfalls and Opportunities},
  publisher = {Wiley},
  year      = {2008},
  address   = {Chichester, UK},
}

@article{shneiderman2020,
  author    = {Ben Shneiderman},
  title     = {Human-Centered Artificial Intelligence: Reliable, Safe \& Trustworthy},
  journal   = {International Journal of Human–Computer Interaction},
  volume    = {36},
  number    = {6},
  pages     = {495--504},
  year      = {2020},
}

@inproceedings{amershi2019,
  author    = {Saleema Amershi and Maya Cakmak and W. Kulesza and et al.},
  title     = {Guidelines for Human--AI Interaction},
  booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages     = {1--13},
  year      = {2019},
}

@article{rahwan2018,
  author    = {Iyad Rahwan},
  title     = {Society-in-the-Loop: Programming the Algorithmic Social Contract},
  journal   = {Ethics and Information Technology},
  volume    = {20},
  number    = {1},
  pages     = {5--14},
  year      = {2018},
}

@article{evans2008,
  author    = {Jonathan St. B. T. Evans},
  title     = {Dual-Process Accounts of Reasoning},
  journal   = {Trends in Cognitive Sciences},
  volume    = {12},
  number    = { dual },
  pages     = {468--475},
  year      = {2008},
}

@book{stanovich2000,
  author    = {Keith E. Stanovich},
  title     = {Individual Differences in Reasoning: Implications for the Rationality Debate?},
  publisher = {Psychology Press},
  year      = {2000},
}

@article{sloman1996,
  author    = {Steven A. Sloman},
  title     = {The Empirical Case for Two Systems of Reasoning},
  journal   = {Psychological Bulletin},
  volume    = {119},
  number    = {1},
  pages     = {3--22},
  year      = {1996},
}

@inproceedings{ott2011,
  title     = {Finding Deceptive Opinion Spam by Any Stretch of the Imagination},
  author    = {Ott, Myle and Choi, Yejin and Cardie, Claire and Hancock, Jeffrey T.},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  year      = {2011},
  pages     = {309--319},
  address   = {Portland, Oregon, USA},
}

@inproceedings{feng2012,
  title     = {Syntactic Stylometry for Deception Detection},
  author    = {Feng, Shi and Banerjee, Runa and Choi, Yejin},
  booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers},
  year      = {2012},
  pages     = {171--180},
  address   = {Jeju, South Korea},
}

@article{perozosas2015,
  title     = {Automatic Deception Detection: Methods for Finding Fake News},
  author    = {Pérez-Rosas, Vanessa and Kleinberg, Benjamin and Lefevre, Alexandre and Mihalcea, Rada},
  journal   = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  year      = {2015},
  pages     = {1566--1576},
}

@inproceedings{zhang2019,
  title     = {Deception Detection in News: A Transformer-Based Approach},
  author    = {Zhang, Xinxing and Zhang, Liang and Zhang, Bo},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
  year      = {2019},
  pages     = {2340--2345},
}
@inproceedings{niculae-etal-2015-linguistic,
    title = "Linguistic Harbingers of Betrayal: A Case Study on an Online Strategy Game",
    author = "Niculae, Vlad  and
      Kumar, Srijan  and
      Boyd-Graber, Jordan  and
      Danescu-Niculescu-Mizil, Cristian",
    editor = "Zong, Chengqing  and
      Strube, Michael",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-1159/",
    doi = "10.3115/v1/P15-1159",
    pages = "1650--1659"
}
@article{perez2022red, title={Red teaming language models with language models}, author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey}, journal={arXiv preprint arXiv:2202.03286}, year={2022} }

@inproceedings{weidinger2022taxonomy,
author = {Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and Biles, Courtney and Brown, Sasha and Kenton, Zac and Hawkins, Will and Stepleton, Tom and Birhane, Abeba and Hendricks, Lisa Anne and Rimell, Laura and Isaac, William and Haas, Julia and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
title = {Taxonomy of Risks posed by Language Models},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533088},
doi = {10.1145/3531146.3533088},
abstract = {Responsible innovation on large-scale Language Models (LMs) requires foresight into and in-depth understanding of the risks these models may pose. This paper develops a comprehensive taxonomy of ethical and social risks associated with LMs. We identify twenty-one risks, drawing on expertise and literature from computer science, linguistics, and the social sciences. We situate these risks in our taxonomy of six risk areas: I. Discrimination, Hate speech and Exclusion, II. Information Hazards, III. Misinformation Harms, IV. Malicious Uses, V. Human-Computer Interaction Harms, and VI. Environmental and Socioeconomic harms. For risks that have already been observed in LMs, the causal mechanism leading to harm, evidence of the risk, and approaches to risk mitigation are discussed. We further describe and analyse risks that have not yet been observed but are anticipated based on assessments of other language technologies, and situate these in the same taxonomy. We underscore that it is the responsibility of organizations to engage with the mitigations we discuss throughout the paper. We close by highlighting challenges and directions for further research on risk evaluation and mitigation with the goal of ensuring that language models are developed responsibly.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {214–229},
numpages = {16},
keywords = {language models, responsible AI, responsible innovation, risk assessment, technology risks},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@article{solaiman2019release,
  title={Release strategies and the social impacts of language models},
  author={Solaiman, Irene and Brundage, Miles and Clark, Jack and Askell, Amanda and Herbert-Voss, Ariel and Wu, Jeff and Radford, Alec and Krueger, Gretchen and Kim, Jong Wook and Kreps, Sarah and others},
  journal={arXiv preprint arXiv:1908.09203},
  year={2019}
}

@inproceedings{danilevsky2020explainability,
    title = "A Survey of the State of Explainable {AI} for Natural Language Processing",
    author = "Danilevsky, Marina  and
      Qian, Kun  and
      Aharonov, Ranit  and
      Katsis, Yannis  and
      Kawas, Ban  and
      Sen, Prithviraj",
    editor = "Wong, Kam-Fai  and
      Knight, Kevin  and
      Wu, Hua",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-main.46/",
    doi = "10.18653/v1/2020.aacl-main.46",
    pages = "447--459",
    abstract = "Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of models becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP). We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area."
}

@article{
vosoughi2018spread,
author = {Soroush Vosoughi  and Deb Roy  and Sinan Aral },
title = {The spread of true and false news online},
journal = {Science},
volume = {359},
number = {6380},
pages = {1146-1151},
year = {2018},
doi = {10.1126/science.aap9559},
URL = {https://www.science.org/doi/abs/10.1126/science.aap9559},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aap9559},
abstract = {There is worldwide concern over false news and the possibility that it can influence political, economic, and social well-being. To understand how false news spreads, Vosoughi et al. used a data set of rumor cascades on Twitter from 2006 to 2017. About 126,000 rumors were spread by ∼3 million people. False news reached more people than the truth; the top 1\% of false news cascades diffused to between 1000 and 100,000 people, whereas the truth rarely diffused to more than 1000 people. Falsehood also diffused faster than the truth. The degree of novelty and the emotional reactions of recipients may be responsible for the differences observed. Science, this issue p. 1146 A large-scale analysis of tweets reveals that false rumors spread further and faster than the truth. We investigated the differential diffusion of all of the verified true and false news stories distributed on Twitter from 2006 to 2017. The data comprise ~126,000 stories tweeted by ~3 million people more than 4.5 million times. We classified news as true or false using information from six independent fact-checking organizations that exhibited 95 to 98\% agreement on the classifications. Falsehood diffused significantly farther, faster, deeper, and more broadly than the truth in all categories of information, and the effects were more pronounced for false political news than for false news about terrorism, natural disasters, science, urban legends, or financial information. We found that false news was more novel than true news, which suggests that people were more likely to share novel information. Whereas false stories inspired fear, disgust, and surprise in replies, true stories inspired anticipation, sadness, joy, and trust. Contrary to conventional wisdom, robots accelerated the spread of true and false news at the same rate, implying that false news spreads more than the truth because humans, not robots, are more likely to spread it.}}

@article{PARK2024100988,
title = {AI deception: A survey of examples, risks, and potential solutions},
journal = {Patterns},
volume = {5},
number = {5},
pages = {100988},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100988},
url = {https://www.sciencedirect.com/science/article/pii/S266638992400103X},
author = {Peter S. Park and Simon Goldstein and Aidan O’Gara and Michael Chen and Dan Hendrycks},
abstract = {Summary
This paper argues that a range of current AI systems have learned how to deceive humans. We define deception as the systematic inducement of false beliefs in the pursuit of some outcome other than the truth. We first survey empirical examples of AI deception, discussing both special-use AI systems (including Meta’s CICERO) and general-purpose AI systems (including large language models). Next, we detail several risks from AI deception, such as fraud, election tampering, and losing control of AI. Finally, we outline several potential solutions: first, regulatory frameworks should subject AI systems that are capable of deception to robust risk-assessment requirements; second, policymakers should implement bot-or-not laws; and finally, policymakers should prioritize the funding of relevant research, including tools to detect AI deception and to make AI systems less deceptive. Policymakers, researchers, and the broader public should work proactively to prevent AI deception from destabilizing the shared foundations of our society.}
}

@inproceedings{
wen2025language,
title={Language Models Learn to Mislead Humans via {RLHF}},
author={Jiaxin Wen and Ruiqi Zhong and Akbir Khan and Ethan Perez and Jacob Steinhardt and Minlie Huang and Samuel R. Bowman and He He and Shi Feng},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=xJljiPE6dg}
}

@misc{amodei2016concreteproblemsaisafety,
      title={Concrete Problems in AI Safety}, 
      author={Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Mané},
      year={2016},
      eprint={1606.06565},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1606.06565}, 
}

@inproceedings{
kim2024system,
title={System-2 Reasoning via Generality and Adaptation},
author={Sejin Kim and Sundong Kim},
booktitle={The First Workshop on System-2 Reasoning at Scale, NeurIPS'24},
year={2024},
url={https://openreview.net/forum?id=brqBUZpj3K}
}

@inproceedings{
bakhtin2021nopress,
title={No-Press Diplomacy from Scratch},
author={Anton Bakhtin and David Wu and Adam Lerer and Noam Brown},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=Pq7wIzt3OUE}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423/",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
}
@article{hanoch2021scams,
author = {Yaniv Hanoch and Stacey Wood},
title ={The Scams Among Us: Who Falls Prey and Why},

journal = {Current Directions in Psychological Science},
volume = {30},
number = {3},
pages = {260-266},
year = {2021},
doi = {10.1177/0963721421995489},
URL = { 
    
        https://doi.org/10.1177/0963721421995489
},
eprint = { 
    
        https://doi.org/10.1177/0963721421995489
}
,
    abstract = { Not a week goes by without stories about scams appearing in popular media outlets. Given the ease with which scams can be circulated, they have become one of the most common crimes globally, inflicting high emotional, financial, and psychological tolls on millions of individuals. Despite their profound and pervasive impact, researchers know relatively little about why some individuals fall victim to scams but others remain immune to the techniques utilized by scammers to lure potential victims. For example, research thus far provides mixed results about the impact of demographic characteristics (e.g., age) as well as personality variables (e.g., risk taking) on individuals’ susceptibility to scams. Even less is known about how the nature or type of scam affects an individual’s susceptibility. Gaining a deeper understanding of these issues is the key to being able to develop preventive programs and reduce the prevalence of victimization. Here, we discuss some promising directions, existing gaps in current knowledge, and the need for decision scientists to address this important problem. }
}

@article{muscanell2014weapons,
  title={Weapons of influence misused: A social influence analysis of why people fall prey to internet scams},
  author={Muscanell, Nicole L and Guadagno, Rosanna E and Murphy, Shannon},
  journal={Social and Personality Psychology Compass},
  volume={8},
  number={7},
  pages={388--396},
  year={2014},
  publisher={Wiley Online Library}
}
@article{garrett2019public,
  title={Public perceptions of Internet-based health scams, and factors that promote engagement with them},
  author={Garrett, Bernie and Mallia, Emilie and Anthony, Joseph},
  journal={Health \& Social Care in the Community},
  volume={27},
  number={5},
  pages={e672--e686},
  year={2019},
  publisher={Wiley Online Library}
}







@article{burnes2017prevalence,
author = {Burnes, David and Henderson, Charles R. and Sheppard, Christine and Zhao, Rebecca and Pillemer, Karl and Lachs, Mark S.},
title = {Prevalence of Financial Fraud and Scams Among Older Adults in the United States: A Systematic Review and Meta-Analysis},
journal = {American Journal of Public Health},
volume = {107},
number = {8},
pages = {e13-e21},
year = {2017},
doi = {10.2105/AJPH.2017.303821},
    note ={PMID: 28640686},

URL = { 
    
        https://doi.org/10.2105/AJPH.2017.303821
    
    

},
eprint = { 
    
        https://doi.org/10.2105/AJPH.2017.303821
    
    

}
,
    abstract = { Background. The financial exploitation of older adults was recently recognized by the Centers for Disease Control and Prevention as a serious public health problem. Knowledge of the prevalence of elder financial exploitation is mostly limited to the category of financial abuse, which occurs in relationships involving an expectation of trust. Little is known about the other major category of elder financial exploitation—elder financial fraud and scams, which is perpetrated by strangers. A valid estimate of elder financial fraud–scam prevalence is necessary as a foundation for research and prevention efforts.Objectives. To estimate the prevalence of elder financial fraud–scam victimization in the United States based on a systematic review and meta-analysis.Search Methods. Multiple investigators independently screened titles and abstracts and reviewed relevant full-text records from PubMed, Medline, PsycINFO, Criminal Justice Abstracts, Social Work Abstracts, and AgeLine databases.Selection Criteria. To maximize the validity and generalizability of prevalence estimation, we restricted eligibility to general population-based studies (English speaking, 1990 onward) using state- or national-level probability sampling and collecting data directly from older adults.Data Collection and Analysis. Information on elder financial fraud–scam prevalence and study-level characteristics was extracted independently by 2 investigators. Meta-analysis of elder financial fraud–scam prevalence used generalized mixed models with individual studies as levels of a random classification factor.Main Results. We included 12 studies involving a total of 41 711 individuals in the meta-analysis. Overall pooled elder financial fraud–scam prevalence (up to 5-year period) across studies was 5.6\% (95\% confidence interval [CI] = 4.0\%, 7.8\%), with a 1-year period prevalence of 5.4\% (95\% CI = 3.2\%, 7.6\%). Studies using a series of questions describing specific fraud–scam events to measure victimization found a significantly higher prevalence (7.1\%; 95\% CI = 4.8\%, 9.4\%) than studies using a single, general-question self-report assessment approach (3.6\%; 95\% CI = 1.8\%, 5.4\%).Author’s Conclusions. Elder financial fraud and scams is a common problem, affecting approximately 1 of every 18 cognitively intact, community-dwelling older adults each year; it requires further attention from researchers, clinicians, and policymakers. Elder financial fraud–scam prevalence findings in this study likely underestimate the true population prevalence. We provide methodological recommendations to limit older adult participation and reporting bias in future population-based research.Public Health Implications. Elder financial exploitation victimization is associated with mortality, hospitalization, and poor physical and mental health. Health care professionals working with older adults likely routinely encounter patients who are fraud–scam victims. Validation of instruments to screen for elder financial fraud and scams in clinical settings is an important area of future research. Without effective primary prevention strategies, the absolute scope of this problem will escalate with the growing population of older adults. }
}


@article{atkins2013study,
  title={A study of social engineering in online frauds},
  author={Atkins, Brandon and Huang, Wilson and others},
  journal={Open Journal of Social Sciences},
  volume={1},
  number={03},
  pages={23},
  year={2013},
  publisher={Scientific Research Publishing}
}

@article{button2014online,
  title={Online frauds: Learning from victims why they fall for these scams},
  author={Button, Mark and Nicholls, Carol McNaughton and Kerr, Jane and Owen, Rachael},
  journal={Australian \& New Zealand journal of criminology},
  volume={47},
  number={3},
  pages={391--408},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{coluccia2020online,
  title={Online romance scams: relational dynamics and psychological characteristics of the victims and scammers. A scoping review},
  author={Coluccia, Anna and Pozza, Andrea and Ferretti, Fabio and Carabellese, Fulvio and Masti, Alessandra and Gualtieri, Giacomo},
  journal={Clinical practice and epidemiology in mental health: CP \& EMH},
  volume={16},
  pages={24},
  year={2020},
  publisher={Bentham Science Publishers}
}

@article{deception_algorithm,
author = {Serra-Garcia, M. and Gneezy, Uri},
year = {2023},
month = {01},
pages = {},
title = {Improving Human Deception Detection Using Algorithmic Feedback},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.4495855}
}

@inproceedings{hazra-majumder-2024-tell,
    title = "To Tell The Truth: Language of Deception and Language Models",
    author = "Hazra, Sanchaita  and
      Majumder, Bodhisattwa Prasad",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.470/",
    doi = "10.18653/v1/2024.naacl-long.470",
    pages = "8506--8520",
    abstract = "Text-based false information permeates online discourses, yet evidence of people`s ability to discern truth from such deceptive textual content is scarce. We analyze a novel TV game show data where conversations in a high-stake environment between individuals with conflicting objectives result in lies. We investigate the manifestation of potentially verifiable language cues of deception in the presence of objective truth, a distinguishing feature absent in previous text-based deception datasets. We show that there exists a class of detectors (algorithms) that have similar truth detection performance compared to human subjects, even when the former accesses only the language cues while the latter engages in conversations with complete access to all potential sources of cues (language and audio-visual). Our model, built on a large language model, employs a bottleneck framework to learn discernible cues to determine truth, an act of reasoning in which human subjects often perform poorly, even with incentives. Our model detects novel but accurate language cues in many cases where humans failed to detect deception, opening up the possibility of humans collaborating with algorithms and ameliorating their ability to detect the truth."
}


@article{lin-etal-2024-decision,
    title = "Decision-Oriented Dialogue for Human-{AI} Collaboration",
    author = "Lin, Jessy  and
      Tomlin, Nicholas  and
      Andreas, Jacob  and
      Eisner, Jason",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "12",
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.tacl-1.50/",
    doi = "10.1162/tacl_a_00679",
    pages = "892--911",
    abstract = "We describe a class of tasks called decision-oriented dialogues, in which AI assistants such as large language models (LMs) must collaborate with one or more humans via natural language to help them make complex decisions. We formalize three domains in which users face everyday decisions: (1) choosing an assignment of reviewers to conference papers, (2) planning a multi-step itinerary in a city, and (3) negotiating travel plans for a group of friends. In each of these settings, AI assistants and users have disparate abilities that they must combine to arrive at the best decision: Assistants can access and process large amounts of information, while users have preferences and constraints external to the system. For each task, we build a dialogue environment where agents receive a reward based on the quality of the final decision they reach. We evaluate LMs in self-play and in collaboration with humans and find that they fall short compared to human assistants, achieving much lower rewards despite engaging in longer dialogues. We highlight a number of challenges models face in decision-oriented dialogues, ranging from goal-directed behavior to reasoning and optimization, and release our environments as a testbed for future work."
}

@article{hadfield2016cooperative,
  title={Cooperative inverse reinforcement learning},
  author={Hadfield-Menell, Dylan and Russell, Stuart J and Abbeel, Pieter and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{lin2022inferring,
  title={Inferring rewards from language in context},
  author={Lin, Jessy and Fried, Daniel and Klein, Dan and Dragan, Anca},
  journal={arXiv preprint arXiv:2204.02515},
  year={2022}
}

@article{jeon2020reward,
  title={Reward-rational (implicit) choice: A unifying formalism for reward learning},
  author={Jeon, Hong Jun and Milli, Smitha and Dragan, Anca},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4415--4426},
  year={2020}
}

@inproceedings{brown2019deep,
  title={Deep counterfactual regret minimization},
  author={Brown, Noam and Lerer, Adam and Gross, Sam and Sandholm, Tuomas},
  booktitle={International conference on machine learning},
  pages={793--802},
  year={2019},
  organization={PMLR}
}

@article{zinkevich2007regret,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

@inproceedings{bade-etal-2024-social,
    title = "Social Media Fake News Classification Using Machine Learning Algorithm",
    author = "Bade, Girma  and
      Kolesnikova, Olga  and
      Sidorov, Grigori  and
      Oropeza, Jos{\'e}",
    editor = "Chakravarthi, Bharathi Raja  and
      Priyadharshini, Ruba  and
      Madasamy, Anand Kumar  and
      Thavareesan, Sajeetha  and
      Sherly, Elizabeth  and
      Nadarajan, Rajeswari  and
      Ravikiran, Manikandan",
    booktitle = "Proceedings of the Fourth Workshop on Speech, Vision, and Language Technologies for Dravidian Languages",
    month = mar,
    year = "2024",
    address = "St. Julian's, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.dravidianlangtech-1.4/",
    pages = "24--29",
    abstract = "The rise of social media has facilitated easier communication, information sharing, and current affairs updates. However, the prevalence of misleading and deceptive content, commonly referred to as fake news, poses a significant challenge. This paper focuses on the classification of fake news in Malayalam, a Dravidian language, utilizing natural language processing (NLP) techniques. To develop a model, we employed a random forest machine learning method on a dataset provided by a shared task(DravidianLangTech@EACL 2024)1. When evaluated by the separate test dataset, our developed model achieved a 0.71 macro F1 measure."
}

@inproceedings{panda-levitan-2022-improving,
    title = "Improving Cross-domain, Cross-lingual and Multi-modal Deception Detection",
    author = "Panda, Subhadarshi  and
      Levitan, Sarah Ita",
    editor = "Louvan, Samuel  and
      Madotto, Andrea  and
      Madureira, Brielen",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-srw.30/",
    doi = "10.18653/v1/2022.acl-srw.30",
    pages = "383--390",
    abstract = "With the increase of deception and misinformation especially in social media, it has become crucial to be able to develop machine learning methods to automatically identify deceptive language. In this proposal, we identify key challenges underlying deception detection in cross-domain, cross-lingual and multi-modal settings. To improve cross-domain deception classification, we propose to use inter-domain distance to identify a suitable source domain for a given target domain. We propose to study the efficacy of multilingual classification models vs translation for cross-lingual deception classification. Finally, we propose to better understand multi-modal deception detection and explore methods to weight and combine information from multiple modalities to improve multi-modal deception classification."
}

@inproceedings{bernard-mickus-2023-many,
    title = "So many design choices: Improving and interpreting neural agent communication in signaling games",
    author = "Bernard, Timoth{\'e}e  and
      Mickus, Timothee",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.531/",
    doi = "10.18653/v1/2023.findings-acl.531",
    pages = "8399--8413",
    abstract = "Emergent language games are experimental protocols designed to model how communication may arise among a group of agents. In this paper, we focus on how to improve performances of neural agents playing a signaling game: a sender is exposed to an image and generates a sequence of symbols that is transmitted to a receiver, which uses it to distinguish between two images, one that is semantically related to the original image, and one that is not. We consider multiple design choices, such as pretraining the visual components of the agents, introducing regularization terms, how to sample training items from the dataset, and we study how these different choices impact the behavior and performances of the agents. To that end, we introduce a number of automated metrics to measure the properties of the emergent language. We find that some implementation choices are always beneficial, and that the information that is conveyed by the agents' messages is shaped not only by the game, but also by the overall design of the agents as well as seemingly unrelated implementation choices."
}

@inproceedings{grover-etal-2024-navigating,
    title = "Navigating Hallucinations for Reasoning of Unintentional Activities",
    author = "Grover, Shresth  and
      Vineet, Vibhav  and
      Rawat, Yogesh S",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.565/",
    doi = "10.18653/v1/2024.findings-emnlp.565",
    pages = "9666--9680",
    abstract = "In this work we present a novel task of understanding unintentional human activities in videos. We formalize this problem as a reasoning task under zero-shot scenario, where given a video of an unintentional activity we want to know why it transitioned from intentional to unintentional. We first evaluate the effectiveness of current state-of-the-art Large Multimodal Models on this reasoning task and observe that they suffer from hallucination. We further propose a novel prompting technique, termed as Dream of Thoughts (DoT), which allows the model to navigate through hallucinated thoughts to achieve better reasoning. To evaluate the performance on this task, we also introduce three different specialized metrics designed to quantify the models reasoning capability. We perform our experiments on three datasets, OOPs, UCF-Crimes, and ReUAct, and our findings show that DOT prompting technique is able to outperform standard prompting, while minimizing hallucinations."
}

@misc{huschens2023trustchatgptperceived,
      title={Do You Trust ChatGPT? -- Perceived Credibility of Human and AI-Generated Content}, 
      author={Martin Huschens and Martin Briesch and Dominik Sobania and Franz Rothlauf},
      year={2023},
      eprint={2309.02524},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2309.02524}, 
}

@inproceedings{Niculae:Kumar:Boyd-Graber:Danescu-Niculescu-Mizil-2015,
Title = {Linguistic Harbingers of Betrayal: A Case Study on an Online Strategy Game},
Author = {Vlad Niculae and Srijan Kumar and Jordan Boyd-Graber and Cristian Danescu-Niculescu-Mizil},
Booktitle = {Association for Computational Linguistics},
Year = {2015},
Location = {Beijing, China},
Url = {http://cs.umd.edu/~jbg//docs/2015_acl_diplomacy.pdf},
}

@inproceedings{lai2020chicago,
  title={" Why is' Chicago'deceptive?" Towards Building Model-Driven Tutorials for Humans},
  author={Lai, Vivian and Liu, Han and Tan, Chenhao},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2020}
}
@article{inan2025betterslowsorryintroducing,
      title={Better Slow than Sorry: Introducing Positive Friction for Reliable Dialogue Systems}, 
      author={Mert İnan, Anthony Sicilia, Suvodip Dey, Vardhan Dongre, Tejas Srinivasan, 
        Jesse Thomason, Gökhan Tür, Dilek Hakkani-Tür, Malihe Alikhani},
      year={2025},
      eprint={2501.17348},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.17348}, 
}
@article{campbell2002deepblue,
author = {Campbell, Murray and Hoane, A. Joseph and Hsu, Feng-hsiung},
title = {Deep Blue},
year = {2002},
issue_date = {January 2002},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {134},
number = {1–2},
issn = {0004-3702},
url = {https://doi.org/10.1016/S0004-3702(01)00129-1},
doi = {10.1016/S0004-3702(01)00129-1},
abstract = {Deep Blue is the chess machine that defeated then-reigning World Chess Champion Garry Kasparov in a six-game match in 1997. There were a number of factors that contributed to this success, including: a single-chip chess search engine, a massively parallel system with multiple levels of parallelism, a strong emphasis on search extensions, a complex evaluation function, and effective use of a Grandmaster game database. This paper describes the Deep Blue system, and gives some of the rationale that went into the design decision behind Deep Blue. Copyright 2001 Elsevier B.V.},
journal = {Artif. Intell.},
month = jan,
pages = {57–83},
numpages = {27},
keywords = {selective search, search extensions, parallel search, game tree search, evaluation function, computer chess}
}

@article{Silver2016MasteringTG,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and L. Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Vedavyas Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy P. Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  journal={Nature},
  year={2016},
  volume={529},
  pages={484-489},
  url={https://api.semanticscholar.org/CorpusID:515925}
}
@inproceedings{Achiam2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haim-ing Bao and Mo Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Made-laine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Benjamin Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Sim'on Posada Fishman and Juston Forte and Is-abella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Raphael Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Lukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Hendrik Kirchner and Jamie Ryan Kiros and Matthew Knight and Daniel Kokotajlo and Lukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Li and Rachel Lim and Molly Lin and Stephanie Lin and Ma-teusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and An-drey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel P. Mossing and Tong Mu and Mira Murati and Oleg Murk and David M'ely and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Ouyang Long and Cullen O'Keefe and Jakub W. Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alexandre Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Pond{\'e} de Oliveira Pinto and Michael Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack W. Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario D. Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas A. Tezak and Madeleine Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cer'on Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll L. Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qim-ing Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:257532815}
}
@inproceedings{Brown2020fewshot,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}
@article{Wei2022EmergentAO,
  title={Emergent Abilities of Large Language Models},
  author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  journal={ArXiv},
  year={2022},
  volume={abs/2206.07682},
  url={https://api.semanticscholar.org/CorpusID:249674500}
}

@article{Ji2022SurveyOH,
  title={Survey of Hallucination in Natural Language Generation},
  author={Ziwei Ji and Nayeon Lee and Rita Frieske and Tiezheng Yu and Dan Su and Yan Xu and Etsuko Ishii and Yejin Bang and Delong Chen and Wenliang Dai and Andrea Madotto and Pascale Fung},
  journal={ACM Computing Surveys},
  year={2022},
  volume={55},
  pages={1 - 38},
  url={https://api.semanticscholar.org/CorpusID:246652372}
}
@article{Buoniu2008ACS,
  title={A Comprehensive Survey of Multiagent Reinforcement Learning},
  author={Lucian Buşoniu and Robert Babuska and Bart De Schutter},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  year={2008},
  volume={38},
  pages={156-172},
  url={https://api.semanticscholar.org/CorpusID:206794869}
}

@article{Shapley1953StochasticG,
  title={Stochastic Games*},
  author={Lloyd S. Shapley},
  journal={Proceedings of the National Academy of Sciences},
  year={1953},
  volume={39},
  pages={1095 - 1100},
  url={https://api.semanticscholar.org/CorpusID:263414073}
}

@inproceedings{Cialdini1993InfluenceTP,
  title={Influence: The Psychology of Persuasion},
  author={Robert B. Cialdini},
  year={1993},
  url={https://api.semanticscholar.org/CorpusID:141645804}
}
@book{10.5555/3312046,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
isbn = {0262039249},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA},
abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}